{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb89d64c",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import swish\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22f6ea",
   "metadata": {},
   "source": [
    "# Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d5594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, img_size=(32, 32)):\n",
    "    classes = ['Normal', 'Reversal', 'Corrected']\n",
    "    X, y = [], []\n",
    "    \n",
    "    for split in ['Train', 'Test']:\n",
    "        split_path = os.path.join(data_dir, split)\n",
    "        for label, class_name in enumerate(classes):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "                img = cv2.resize(img, img_size)  # Resize to 32x32\n",
    "                img = img / 255.0  # Normalize pixel values to [0,1]\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "    \n",
    "    X = np.array(X).reshape(-1, 32, 32, 1)  # Reshape for CNN input\n",
    "    y = to_categorical(y, num_classes=len(classes))  # Convert labels to one-hot encoding\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c681263",
   "metadata": {},
   "source": [
    "# Define the Modified LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(6, (5, 5), activation=swish, padding='same', input_shape=(32, 32, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(16, (5, 5), activation=swish, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(120, (5, 5), activation=swish, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(84, activation=swish),\n",
    "        Dropout(0.1),\n",
    "        Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71bcbb",
   "metadata": {},
   "source": [
    "# Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"Gambo\"\n",
    "X_train, X_test, y_train, y_test = load_dataset(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2132e",
   "metadata": {},
   "source": [
    "# Instantiate and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44eae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83def50",
   "metadata": {},
   "source": [
    "# Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00511864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c83e7",
   "metadata": {},
   "source": [
    "# Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12506b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f302dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
